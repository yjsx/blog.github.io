<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>0001 PanopticFusion:Online Volumetric Semantic Mapping at the Level of Stuff and Things</title>
    <url>/2022/05/27/0001/</url>
    <content><![CDATA[<p><em>作者:Gaku Narita, Takashi Seno, Tomoya Ishikawa, Yohsuke Kaji</em><br><em>机构:sony</em><br><em>发表:IROS 2019</em></p>
<p><strong>Abstract</strong><br>我们提出了PanopticFusion, 一个新的volumetric 语义建图系统，在stuff和things的层次上。stuff代表背景，things代表前景。除此之外，该系统可以重建大规模场景，并且可以提取有标签的mesh，因为其用了 spatially hashed volumetric 的地图表示形式。我们的系统首先对输入的RGB图像预测像素级的panoptic label（背景为class，前景为实例ID），通过融合2D语义和实例分割的输出。预测的panoptic标签和深度一起被融合进volumetric map，于此同时保持了帧间一致性。除此之外，我们构建了全连接CRF，用于地图regularization。对于在线的CRF推断，我们提出了一个新的一元势近似和地图划分策略。</p>
<p>我们在ScanNet（v2）中验证了性能。 </p>
<span id="more"></span>

<p><strong>一些信息：</strong></p>
<ol>
<li>使用数据集为ScanNet V2</li>
<li>对比的算法有SLAM++，2.5D is not enough，SemanticFusion，DA-RNN，MaskFusion，Fusion++</li>
<li>地图的表示方法为 Real-time 3d reconstruction at scale using voxel hashing中的方法（2013 ToG）</li>
<li>建图方法为voxblox（ Voxblox: Incremental 3d euclidean signed distance fields for on-board mav planning 2017 IROS）</li>
<li>使用的网络为PSPNet和Mask R-CNN</li>
</ol>
<img src="/2022/05/27/0001/1.png" class>
<img src="/2022/05/27/0001/2.png" class>

]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>semantic</tag>
        <tag>RGBD</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title>0002. Panoptic Neural Fields:A Semantic Object-Aware Neural Scene Representation</title>
    <url>/2022/05/30/0002/</url>
    <content><![CDATA[<p><em>作者:Abhijit Kundu, Kyle Genova, Xiaoqi Yin, Alireza Fathi,Caroline Pantofaru, Leonidas Guibas, Andrea Tagliasacchi, Frank Dellaert, Thomas Funkhouser</em><br><em>机构:Google Research + Georgia Tech+Simon Fraser University + Stanford University</em><br><em>发表: CVPR 2022</em></p>
<p><strong>Abstract</strong><br>我们提出了Panoptic Neural Fields (PNF)，一个object-aware的neural的场景表示，可以结构一个场景变成一组物体（thing）和背景（stuff）。每一个物体被表示为一个有朝向的3D bbox和一个多层感知机（输入位置方向和时间，输出密度和辐射）。stuff被表示为一个简单的MLP，输出语义标签。每一个物体MLP是实例1的，因此可以比之前的物体感知方法更小更快，于此同时通过元学习初始化，保持特定类别的先验。我们的模型仅从RGB图像就可以构建了一个panoptic radiance field来对任何场景进行表示。我们使用了现成的算法来预测相机位姿，物体轨迹和2D图像语义分割。然后我们使用基于颜色图像的自监督和基于预测语义分割的伪监督的综合分析，来联合优化MLP的参数，和bbox的参数。在真实世界的动态场景中的实验里，我们发现我们的模型可以被用来高效地完成比如视角合成，2D panoptic 分割，3D场景编辑和多视角深度估计等。</p>
<span id="more"></span>

<p><strong>一些信息：</strong></p>
<ol>
<li>对标的算法有 <ul>
<li>MeshRCNN,Total3D,</li>
<li>Atlas,SLAM++,PanopticFusion,Kimera,DynSceneGraphs,</li>
<li>SemanticNerf,NSG,ObjectNeRF</li>
</ul>
</li>
<li>本篇为NeRF流的</li>
</ol>
<img src="/2022/05/30/0002/1.png" class>
<img src="/2022/05/30/0002/2.png" class>
<img src="/2022/05/30/0002/3.png" class>
<img src="/2022/05/30/0002/4.png" class>

]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>semantic</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title>0003 SO-SLAM:Semantic Object SLAM with Scale Proportional and Symmetrical Texture Constraints</title>
    <url>/2022/05/30/0003/</url>
    <content><![CDATA[<p><em>作者:Ziwei Liao, Yutong Hu, Jiadong Zhang, Xianyu Qi, Xiaoyu Zhang, Wei Wang</em><br><em>机构:北航</em><br><em>发表:RAL ICRA 2022</em></p>
<p><strong>Abstract</strong><br>Object-SLAM可以帮助移动机器人理解室内场景和物体级别的交互应用。SOTA的物体级SLAM面临着一些挑战，比如部分观测，遮挡，不可观测等问题，限制着建图精确度和鲁棒性。本文提出了一个新的单目语义物体SLAM——SO-SLAM，解决了引入物体空间约束。我们探索了三种代表性的空间约束包括尺度约束，对称纹理约束和平面约束。基于这些语义约束，我们提出了两个新的方法，一个更鲁棒的物体初始化方法，和一个方向精细优化的方法。我们在数据集和真实数据上验证了算法的性能。并进行了开源<a href="https://github.com/XunshanMan/SoSLAM%E3%80%82">https://github.com/XunshanMan/SoSLAM。</a></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>物体检测使用YOLO</li>
</ol>
<img src="/2022/05/30/0003/1.png" class>

]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>object</tag>
        <tag>单目</tag>
      </tags>
  </entry>
  <entry>
    <title>0004 Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery</title>
    <url>/2022/05/30/0004/</url>
    <content><![CDATA[<p><em>作者:Margarita Grinvald, Fadri Furrer, Tonci Novkovic, Jen Jen Chung, Cesar Cadena, Roland Siegwart, Juan Nieto</em><br><em>机构:ETHZ</em><br><em>发表:RAL IROS 2019</em></p>
<p><strong>Abstract</strong><br>在建图时，除了构建场景的几何表示，对环境更高级的理解是检测到更高级的实例对象。这项工作提出了一种在RGBD相机实时扫描过程中，增量构建volumetric 以物体为中心的地图。首先，每一帧的分割结合了无监督几何方法与实例分割预测来识别场景元素和检测之前未见过的物体。随后，一个数据关联track了不同帧中的被预测的物体。最后，一个地图融合策略融合了它们的3D形状，位置，语义类别 于一个全局volume。在公开数据集上的测试，证明了这种方法已经可以和SOTA竞争，同时可以发现，之前未看到的种类。系统在实际中也进行了测试，展现了其实时性。并进行了开源<a href="https://github.com/ethz-asl/voxblox-plusplus">https://github.com/ethz-asl/voxblox-plusplus</a>.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>本项工作对每帧进行如下四步操作：<ol>
<li>几何分割：convexity-based方法（将点云，划分为若干个凸集）</li>
<li>实例语义分割：RGB使用Mask RCNN进行打标签，并根据第一步中的结果进行合并</li>
<li>数据关联：当前帧与地图进行匹配</li>
<li>地图融合：合并到地图中</li>
</ol>
</li>
<li>一个假设：相机位姿已知<img src="/2022/05/30/0004/1.png" class>
<img src="/2022/05/30/0004/2.png" class></li>
</ol>
]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>RGBD</tag>
        <tag>object</tag>
        <tag>instance</tag>
      </tags>
  </entry>
  <entry>
    <title>0005 Hierarchical Object Map Estimation for Efficient and Robust Navigation</title>
    <url>/2022/05/30/0005/</url>
    <content><![CDATA[<p><em>作者:Kyel Ok, Katherine Liu, and Nicholas Roy</em><br><em>机构:MIT</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>我们提出了一个物体的分层次表示的方法，随着测量的累计，物体的表示可以进行改变。我们初始估计每个物体为一个2Dbbox或者一个3D点，用来描述几何性质（从有限的视角即可获得）。随着更多的测量，我们允许每个物体变成更高维的3D体素模型，来提高重建精度和碰撞检测。我们的 Hierarchical Object Map Estimation (HOME) 对视角上的缺陷是鲁棒的，可以规划出围绕障碍物的安全高效轨迹。在TUM数据集上进行了验证。</p>
<span id="more"></span>

<p><strong>一些信息：</strong></p>
<ol>
<li>一篇为导航设计的建图算法，对物体模型的构建由粗到细</li>
</ol>
<img src="/2022/05/30/0005/1.png" class>
<img src="/2022/05/30/0005/2.png" class>

]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
      </tags>
  </entry>
  <entry>
    <title>0006 Towards Real-time Semantic RGB-D SLAM in Dynamic Environments</title>
    <url>/2022/05/30/0006/</url>
    <content><![CDATA[<p><em>作者: Tete Ji, Chen Wang, and Lihua Xie</em><br><em>机构: NTU+CMU</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>现有的VSLAM框架大多依赖静态环境，在动态环境中很容易失效。一些最近的工作使用深度学习得到语义信息来避免动态物体的影响，但是这些方法一般有着很高的计算开销，并且不能处理没有见过的物体。在本篇文章中，我们提出了一个实时的语义RGBD SLAM，可以处理见过或没见过的动态物体。为了减少计算开销，我们只对关键帧进行语义分割以剔除已知动态物体，并维护一个静态地图。除此之外，我们提出了一个高效的几何模块来检测未知的动态物体，具体方法为将深度图像聚类并通过重投影误差来识别动态区域。提出的方法在数据集以及真实场景进行测试。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>几何方法加语义方法，提升SLAM性能</li>
</ol>
<img src="/2022/05/30/0006/1.png" class>
<img src="/2022/05/30/0006/2.png" class>
<img src="/2022/05/30/0006/3.png" class>
<img src="/2022/05/30/0006/4.png" class>


]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>semantic</tag>
        <tag>RGBD</tag>
        <tag>dynamic</tag>
      </tags>
  </entry>
  <entry>
    <title>0007 SoftGroup for 3D Instance Segmentation on Point Clouds</title>
    <url>/2022/05/30/0007/</url>
    <content><![CDATA[<p><em>作者:Thang Vu, Kookhoi Kim, Tung M. Luu, Xuan Thanh Nguyen, Chang D. Yoo</em><br><em>机构:KAIST</em><br><em>发表:CVPR 2022</em></p>
<p><strong>Abstract</strong><br>现存的SOTA实例分割方法使用grouping。hard预测将每个点与每个单独的种类相关联。然而，来自硬决策的错误，导致了（1）预测的实例与GT的低重叠度（2）大量的假阳性。</p>
<p>为了解决这些问题，本文提出了一个名为SoftGroup的3D实例分割算法，先自底向上的grouping，再自顶向下的refine。SoftGroup允许每个点被关联到不同的种类，来缓解语义预测的错误和FP，通过学习将其种类变为背景。实验展示了在不同数据集和多种评价指标下证明其效用。在ScanNetV2上超过最好6.2%，在S3DIS上超过最好6.8%.在Titan X上，每帧推算时间为345ms。开源： <a href="https://github.com/thangvubk/SoftGroup.git">https://github.com/thangvubk/SoftGroup.git</a></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>目前实例分割的SOTA</li>
<li>group流</li>
<li>自底向上，逐点预测语义和offset。soft grouping 将其处理为 实例proposal。自顶向下，提取到的特征被用来预测类别，实例掩码，掩码分数来作为最后的结果。<img src="/2022/05/30/0007/1.png" class>
<img src="/2022/05/30/0007/2.png" class>
<img src="/2022/05/30/0007/3.png" class></li>
</ol>
]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>instance</tag>
        <tag>point cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>0008 PointGroup:Dual-Set Point Grouping for 3D Instance Segmentation</title>
    <url>/2022/05/30/0008/</url>
    <content><![CDATA[<p><em>作者:Li Jiang, Hengshuang Zhao, Shaoshuai Shi1 Shu Liu, Chi-Wing Fu, Jiaya Jia</em><br><em>机构:港中文+smartmore</em><br><em>发表:CVPR2020</em></p>
<p><strong>Abstract</strong><br>与2D实例分割相比，3D还有很多提升空间。在本文中，我们提出了PointGroup，一个新的端到端，自下而上的架构，关注探索物体之间的空隙以更好地group点。我们设计了两个分支的网络，来提取点云特征，并预测语义label和与实例中心之间的offset。一个聚类组件，使用原始和偏移过后的点集，利用它们互补的优势。更进一步，我们搭建了ScoreNet来评估instance候选者，并用NMS来去除重复数据。我们在ScanNet和S3DIS上进行了实验。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>实例分割分两步走，首先将3D空间划分为单独的物体，第二部为为每个物体打上标签。</li>
<li>与2D卷积不同的是，没有遮挡问题，且物体会自然地被空区域所分割<img src="/2022/05/30/0008/1.png" class>
<img src="/2022/05/30/0008/2.png" class></li>
</ol>
]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>instance</tag>
        <tag>point cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>0009 ScanNet:Richly-annotated 3D Reconstructions of Indoor Scenes</title>
    <url>/2022/05/30/0009/</url>
    <content><![CDATA[<p><em>作者:Angela Dai, Angel X. Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, Matthias Nießner</em><br><em>机构:Stanford University + Princeton University + Technical University of Munich</em><br><em>发表:CVPR 2017</em></p>
<p><strong>Abstract</strong><br>监督学习的关键是一个大型数据集。但是，目前RGB-D场景理解的数据非常少。为了解决这个问题，我们发布了ScanNet，一个RGBD视频数据集，包含了2.5M帧，在1513个场景中，标注了3D相机位姿，表面重建和语义分割。为了收集这个数据，我们设计了易用的RGBD捕捉系统，包含了自动化表面重建和众包的语义标注。我们展示了使用这个数据可以达到SOTA性能，在一些场景理解任务上，包括3D物体识别，语义label，和CAD模型检索。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>支持的任务：3D物体分类，语义分割，3D模型匹配</li>
</ol>
<img src="/2022/05/30/0009/1.png" class>
<img src="/2022/05/30/0009/2.png" class>
<img src="/2022/05/30/0009/3.png" class>

]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>0010 ROCA:Robust CAD Model Retrieval and Alignment from a Single Image</title>
    <url>/2022/05/30/0010/</url>
    <content><![CDATA[<p><em>作者:Can Gümeli, Angela Dai, Matthias Nießner</em><br><em>机构:TUM</em><br><em>发表:CVPR 2022</em></p>
<p><strong>Abstract</strong><br>我们提出了ROCA，一个新的端到端方法从一个形状数据库中检索并对齐3D CAD 模型（来自单张图像中）。这使得可以从2D图像中获得3D感知信息。我们方法的核心是我们的2D-3D物体对应的可微对齐优化和Pro-crustes 对齐.ROCA可以提供一个鲁棒的CAD对齐，同时通过2D-3D的对应学习几何相似性来进行CAD检索。实验在ScanNet上，将SOTA从9.5%提升到了17.6%。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>算法流程：<ol>
<li>输入为RGB图片，相机内参和CAD数据库</li>
<li>目标为输出CAD模型与图像的9DoF对齐参数</li>
<li>首先使用Mask RCNN对其进行语义分割，同时使用multi-scale FPN估计物体深度</li>
<li>随后使用深度，2D特征，instance mask来估计尺度和初始位姿</li>
<li>此外我们建立了与物体规范空间之间的可学习，稠密的对应关系。我们<img src="/2022/05/30/0010/1.png" class>
<img src="/2022/05/30/0010/2.png" class>
</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>一分钟</category>
      </categories>
      <tags>
        <tag>一分钟</tag>
        <tag>Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title>0422 LVI-SAM:Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping</title>
    <url>/2021/04/22/0422-LVI-SAM/</url>
    <content><![CDATA[<p><em>作者: Tixiao Shan, Brendan Englot, Carlo Ratti, and Daniela Rus</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>我们通过SAM(smoothing and mapping)的方式，提出了一个 雷达-视觉-惯导的紧耦合的SLAM框架-LVI-SAM。该框架可以实时进行状态估计和高精度地图的构建。LVI-SAM分为两个部分：视觉惯性系统VIS 和 雷达惯性系统 LIS。这两个子系统均以紧耦合的方式进行设计。两个系统并行的作用如下：</p>
<ol>
<li>VIS利用LIS的估计进行初始化。</li>
<li>通过使用激光雷达的测量结果来优化VIS中视觉特征的深度信息，可以提高VIS的准确性。</li>
<li>LIS也可以利用VIS对位姿的估计，作为点云配准的初始值。</li>
<li>闭环首先由VIS进行识别，再由LIS进行完善</li>
<li>当任意一个系统发生故障时，LVI-SAM仍然可以稳定运行，提高了在缺乏纹理信息和特征区域的鲁棒性。<br>其中VIS以Vins-Mono为基础，LIS以LIO-SAM为基础。整个系统以IMU的速率输出位姿估计的结果。</li>
</ol>
<span id="more"></span>

<p><strong>主要贡献：</strong></p>
<ol>
<li>实现了一个紧耦合的激光-视觉-惯导系统，通过因子图同时完成了多传感器融合和全局优化（包含回环检测）两项任务。</li>
<li>通过故障检测机制，绕过出现问题的子系统，提高了整个系统的鲁棒性。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://github.com/TixiaoShan/LVI-SAM/blob/master/doc/paper.pdf">https://github.com/TixiaoShan/LVI-SAM/blob/master/doc/paper.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/TixiaoShan/LVI-SAM">https://github.com/TixiaoShan/LVI-SAM</a></p>
<img src="/2021/04/22/0422-LVI-SAM/1.png" class>
<img src="/2021/04/22/0422-LVI-SAM/2.png" class>
<img src="/2021/04/22/0422-LVI-SAM/3.png" class>
<img src="/2021/04/22/0422-LVI-SAM/4.png" class>
<img src="/2021/04/22/0422-LVI-SAM/5.png" class>
<img src="/2021/04/22/0422-LVI-SAM/6.png" class>
<img src="/2021/04/22/0422-LVI-SAM/7.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>fusion-slam</tag>
        <tag>code</tag>
      </tags>
  </entry>
  <entry>
    <title>0423 Lightweight 3-D Localization and Mapping for Solid-State LiDAR</title>
    <url>/2021/04/23/0423/</url>
    <content><![CDATA[<p><em>作者: Han Wang , Chen Wang , and Lihua Xie</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>最近由于固态激光雷达的推出为小型机器人提供了一种经济高效且灵活的解决方案。与传统的机械式雷达相比，固态激光雷达拥有更高的频率（注：指本文所用的这一款）和分辨率，但同时缺点是视野（FOV）比较小。这对于现有的激光雷达框架是一个不小的挑战。因此，本文提出了一个新的SLAM，包含了特征提取，激光里程计，地图构建等模块。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ul>
<li>固态雷达SLAM具体的难点：<ul>
<li>固态雷达更高的角分辨率，点云更加稠密，导致传统配准算法如ICP效率低下。</li>
<li>更新频率更高，使得如LOAM等激光SLAM算法在实时性上不能达到要求</li>
<li>视野较小，导致有剧烈旋转的时候，容易导致跟踪的丢失。</li>
</ul>
</li>
<li>本文使用的固态激光雷达为Intel L515，与VLP-16的参数对比如图一所示。</li>
<li>本文的作者Han Wang为FLOAM，ISCLOAM等激光SLAM开源代码的作者</li>
</ul>
<p><strong>主要贡献：</strong><br>1.实现了一个完整的固态激光SLAM框架，并开源。<br>2.提出了一种改进的特征提取算法，可以提取到在旋转情况下，稳定的特征。另外左李导数用于迭代位姿估计，以便以无奇异点的形式表示位姿。<br>3.在AGV小车上以及手持场景，进行了实验。</p>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2102.03800.pdf">https://arxiv.org/pdf/2102.03800.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/wh200720041/ssl_slam2">https://github.com/wh200720041/ssl_slam2</a></p>
<img src="/2021/04/23/0423/1.png" class>
<img src="/2021/04/23/0423/2.png" class>
<img src="/2021/04/23/0423/3.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
        <tag>solid</tag>
        <tag>system</tag>
      </tags>
  </entry>
  <entry>
    <title>0424 Towards Semantic Segmentation of Urban-Scale 3D Point Clouds:A Dataset, Benchmarks and Challenges</title>
    <url>/2021/04/24/0424/</url>
    <content><![CDATA[<p><em>作者: Qingyong Hu, Bo Yang</em>, Sheikh Khalid, Wen Xiao, Niki Trigoni, Andrew Markham*<br><em>发表: CVPR 2021</em></p>
<p><strong>Abstract</strong><br>3D场景理解的监督学习算法的基础是大规模的标注数据。但是，由于数据收集和标注的成本很高，所以公开数据集往往规模都比较小，或者标注的类别不够丰富。这限制了对3D点云细粒度语义理解的发展。在这篇论文中，我们发布了一个城市规模的点云数据集，包含了接近30亿的包含语义信息的点。点云数量是已有数据集的三倍。数据集包含了英国的三个城市（伯明翰，剑桥，约克），约7.6平方千米的覆盖面积。数据被标注成了13个在城市中常见的种类。除此之外，我们对SOTA的算法进行了测试，并且进行分析。最后，文章提出了城市场景语义理解的几个挑战。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>13个标记的种类如下：地面，植被，建筑，墙，桥梁，停车场，铁轨，交通路，街道设施（长凳，电线杆，路灯等），车，人行道，自行车，水。</li>
<li>数据集使用无人机进行录制，飞行路径和区域等见图二。数据集中的点云也包含RGB信息。</li>
<li>对已有SOTA算法的测试结果见图四。</li>
<li>文章末尾提出的点云语义理解的4项挑战：<ol>
<li>对大规模点云的预处理（即如何下采样以塞进内存里）</li>
<li>几何信息与颜色信息对分割算法的影响</li>
<li>类别不平衡</li>
<li>跨城市的泛化能力</li>
</ol>
</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>一个城市规模的3D语义数据集。 </li>
<li>对现有算法的深入分析研究。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2102.03800.pdf">https://arxiv.org/pdf/2102.03800.pdf</a><br><strong>项目首页：</strong><a href="https://github.com/QingyongHu/SensatUrban">https://github.com/QingyongHu/SensatUrban</a><br><strong>数据集地址：</strong><a href="https://forms.gle/m4HJiqZxnq8rmjc8A">https://forms.gle/m4HJiqZxnq8rmjc8A</a></p>
<img src="/2021/04/24/0424/1.png" class>
<img src="/2021/04/24/0424/2.png" class>
<img src="/2021/04/24/0424/3.png" class>
<img src="/2021/04/24/0424/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>semantic</tag>
        <tag>dataset</tag>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>0425 Robust Place Recognition using an Imaging Lidar</title>
    <url>/2021/04/25/0425/</url>
    <content><![CDATA[<p><em>作者: Tixiao Shan, Brendan Englot, Fábio Duarte, Carlo Ratti, and Daniela Rus</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>我们提出了一种鲁棒，实时的重定位方法，使用的传感器为图像级分辨率的激光雷达（128线机械式激光雷达）。利用激光的强度（intensity）数值，我们将点云进行投影，获得一个强度图像。从该图像中提取ORB特征，并编码为bag-of-words（BOW）向量。这个向量可以描述这一帧点云，并且插入由DBOW维护的数据库中。返回的与该向量相似的候选项通过特征匹配进一步进行筛选。通过RANSEC+PnP的方式来拒绝outliers（即计算视觉特征点重投影误差）。这种方法结合了视觉SLAM和激光SLAM在重定位方面的优点，具有旋转不变性，并且可以解决反向或者倒转情况下的重定位问题。所提出的方法在不同的平台和实验环境中得到了验证。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>提出了一个使用雷达点云生成的强度图像的重定位方法。</li>
<li>所提出的方法对于传感器的位姿没有要求，在反向或颠倒的情况下仍然可以运行。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://github.com/TixiaoShan/imaging_lidar_place_recognition">https://github.com/TixiaoShan/imaging_lidar_place_recognition</a><br><strong>开源代码：</strong><a href="https://github.com/TixiaoShan/imaging_lidar_place_recognition/blob/master/doc/paper.pdf">https://github.com/TixiaoShan/imaging_lidar_place_recognition/blob/master/doc/paper.pdf</a></p>
<img src="/2021/04/25/0425/1.png" class>
<img src="/2021/04/25/0425/2.png" class>
<img src="/2021/04/25/0425/3.png" class>
<img src="/2021/04/25/0425/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
        <tag>recognition</tag>
      </tags>
  </entry>
  <entry>
    <title>0426 Efficient LiDAR Odometry for Autonomous Driving</title>
    <url>/2021/04/26/0426/</url>
    <content><![CDATA[<p><em>作者: Xin Zheng, Jianke Zhu</em><br><em>发表: arxiv</em></p>
<p>注：本篇还未正式发表，不过目前在kitti上排名第15，是一篇较新的文章。<br><strong>Abstract</strong><br>雷达里程计（点云配准问题）在激光SLAM中扮演着重要角色。传统基于KD-Tree的搜索方法无法高效地处理大规模的点云（通常使用下采样的方法解决此类问题）。最近基于球面深度图像的方法可以通过球面映射的方式高效地寻找最近邻点，但是无法很好得处理地面点云。为了解决这个问题，我们提出了一种方法，同时使用不包含地面点云的球面深度图和地面点云的鸟瞰图。除此之外，还提出了一种快速估计局部法向量的方法，以及一种新的模型（局部地图）更新方案以融合不同时间戳下的点云以及法向量</p>
<span id="more"></span>
<p><strong>主要贡献：</strong></p>
<ol>
<li>利用非地面球面深度图像与地面点云鸟瞰图的雷达里程计</li>
<li>自适应法向量估计方法</li>
<li>高效的模型更新方法（指局部地图的更新）</li>
<li>在kitti上取得了不错的成绩，且整体的运行速度在笔记本电脑上可以达到恐怖的169Hz</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2104.10879.pdf">https://arxiv.org/pdf/2104.10879.pdf</a></p>
<img src="/2021/04/26/0426/1.png" class>
<img src="/2021/04/26/0426/2.png" class>
<img src="/2021/04/26/0426/3.png" class>
<img src="/2021/04/26/0426/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>Odometry</tag>
      </tags>
  </entry>
  <entry>
    <title>0427 Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments</title>
    <url>/2021/04/27/0427/</url>
    <content><![CDATA[<p>*作者: Siyan Dong *, Qingnan Fan <em>, He Wang, Ji Shi, Li Yi, Thomas Funkhouser, Baoquan Chen, Leonidas Guibas</em><br><em>发表: CVPR 2021</em></p>
<p><strong>Abstract</strong><br>本篇文章关注在动态场景中的重定位问题。估计相机3D位姿的最新进展使用CNN或者决策树进行估计。这两种方法一般使用静态的图像序列，所以对动态的室内物体十分敏感。为了解决这个问题，我们提出了一种新的可以识别outlier的神经树（neural tree），综合了深度学习和决策树两种方法。该方法由三个部分组成：</p>
<ol>
<li>一个按照 分层次划分室内空间 方法构建的决策树；</li>
<li>一个nerual routing function（不知道咋翻译。。。），使用一个目标识别网络实现，以更好得理解场景；（大概思想是将输入沿着neural tree，一直找到相应的叶子节点，这个过程被称作route）</li>
<li>一个离群点拒绝模块，用来过滤动态物体。<br>所提出的算法在RIO-10数据集上得到了验证，比SOTA算法效果好了约30%。<span id="more"></span></li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2012.04746.pdf">https://arxiv.org/pdf/2012.04746.pdf</a></p>
<img src="/2021/04/27/0427/1.png" class>
<img src="/2021/04/27/0427/2.png" class>
<img src="/2021/04/27/0427/3.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>dynamic</tag>
        <tag>每日论文分享</tag>
        <tag>recognition</tag>
        <tag>visual</tag>
        <tag>learning</tag>
      </tags>
  </entry>
  <entry>
    <title>0428 Online Camera-LiDAR Calibration with Sensor Semantic Information</title>
    <url>/2021/04/28/0428/</url>
    <content><![CDATA[<p><em>作者: Yufeng Zhu, Chenghui Li and Yubo Zhang</em><br><em>发表: ICRA 2020</em></p>
<p><strong>Abstract</strong><br>作为数据融合的关键步骤，传感器标定在计算机视觉任务中扮演着重要角色。现有的技术通常需要大量的人力工作和复杂的设置，或者并不鲁棒易于产生次优解。在本文中，我们主要关注相机和激光雷达这两种在室外常用的传感器。我们提出了一种实时在线的标定，可以寻找二者之间最优的刚性位姿变化，而且不需要特殊的环境设置（指放置棋盘格等）。使用一个基于语义特征的新的标定度量标准，我们将标定任务表示为一个最优化问题，成功地将同步的一对数据进行实时对齐。效果达到了SOTA水平。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>使用PSPNet对图像进行语义分割（提取出来汽车的轮廓）。</li>
<li>将图片按照一定的步骤形成height map（如图二）。</li>
<li>通过计算过滤掉地面的点云与height map的重叠部分，来定义标定的qulity metric。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://ieeexplore.ieee.org/document/9196627">https://ieeexplore.ieee.org/document/9196627</a></p>
<img src="/2021/04/28/0428/1.png" class>
<img src="/2021/04/28/0428/2.png" class>
<img src="/2021/04/28/0428/3.png" class>
<img src="/2021/04/28/0428/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>semantic</tag>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>visual</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title>0429 Self-supervised Learning of LiDAR Odometry for Robotic Applications</title>
    <url>/2021/04/30/0429/</url>
    <content><![CDATA[<p><em>作者: Julian Nubert, Shehryar Khattak and Marco Hutter</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>本文提出了一种通用的自监督雷达里程计的估计方法，保证实时性的同时可以充分利用所有可以使用的点云。该方法在训练阶段使用从输入数据中提取的几何损失。除此之外，该方法不需要标注或者ground truth，所以可以方便的在没有ground truth的场景使用。这种网络结构在各种机器人以及室内/外环境的多种数据集上得到了验证，不需要更改损失函数或者网络结构，具有通用性。</p>
<span id="more"></span>
<p><strong>一些信息：</strong><br>使用了两种损失函数，分别为点到平面的距离和平面到平面的距离，如图1所示。</p>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2011.05418.pdf">https://arxiv.org/pdf/2011.05418.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/leggedrobotics/DeLORA">https://github.com/leggedrobotics/DeLORA</a></p>
<img src="/2021/04/30/0429/1.png" class>
<img src="/2021/04/30/0429/2.png" class>
<img src="/2021/04/30/0429/3.png" class>
<img src="/2021/04/30/0429/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
        <tag>learning</tag>
      </tags>
  </entry>
  <entry>
    <title>0430 Towards Real-time Semantic RGB-D SLAM in Dynamic Environments</title>
    <url>/2021/04/30/0430/</url>
    <content><![CDATA[<p><em>作者: Tete Ji, Chen Wang, and Lihua Xie</em><br><em>机构: NTU+CMU</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>现有的VSLAM框架大多依赖静态环境，在动态环境中很容易失效。一些最近的工作使用深度学习得到语义信息来避免动态物体的影响，但是这些方法一般有着很高的计算开销，并且不能处理没有见过的物体。在本篇文章中，我们提出了一个实时的语义RGBD SLAM，可以处理见过或没见过的动态物体。为了减少计算开销，我们只对关键帧进行语义分割以剔除已知动态物体，并维护一个静态地图。除此之外，我们提出了一个高效的几何模块来检测未知的动态物体，具体方法为将深度图像聚类并通过重投影误差来识别动态区域。提出的方法在数据集以及真实场景进行测试。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>整个系统基于ORB-SLAM2，本文工作的目的是剔除属于动态物体的特征点。</li>
<li>语义分割部分使用轻量级网络SegNet。</li>
<li>不需要先验信息的几何模块，使用K-Means算法进行聚类（聚类数量N = 24），随后进行重投影误差的计算，误差大的则视为动态物体。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2104.01316v1.pdf">https://arxiv.org/pdf/2104.01316v1.pdf</a></p>
<img src="/2021/04/30/0430/1.png" class>
<img src="/2021/04/30/0430/2.png" class>
<img src="/2021/04/30/0430/3.png" class>
<img src="/2021/04/30/0430/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>semantic</tag>
        <tag>RGBD</tag>
        <tag>dynamic</tag>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>0501 Pixel-level Extrinsic Self Calibration of High Resolution LiDAR and Camera in Targetless Environment</title>
    <url>/2021/05/01/0501/</url>
    <content><![CDATA[<p><em>作者: Chongjian Yuan, Xiyuan Liu, Xiaoping Hong, Fu Zhang</em><br><em>机构: hku</em><br><em>发表: arxiv</em></p>
<p><strong>Abstract</strong><br>在本文中，我们提出了一种高分辨率雷达和相机之间外参自动标定的方法。我们的方法不需要标定板，而且可以通过对齐两种传感器中的边特征以达到像素级准确度。在理论层面，我们分析了边特征带来的约束，以及标定准确度对环境中边特征分布的敏感度。在实现层面，我们研究了雷达测距的规律，提出了一个基于体素化以及平面拟合的高效准确的提取雷达边特征的方法。由于在自然环境中，边特征十分丰富，所以我们在室内外均进行实验，得到了鲁棒性强，准确性高的实验结果。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>由于相机和雷达位置不一样导致视野有少许差异，文章提出了因为障碍物的存在导致的两种投影问题，zero-valued和multi-valued。前者为相机看见但雷达看不见的区域，导致部分图像上没有点云数据，如图2的A区域；后者为雷达看见而相机看不见的区域，导致本该属于背景物体的点云投影到了前景物体上，如图二的B区域。</li>
<li>为了避免上述问题，提出将线特征分为两类，深度连续和深度不连续，如图3所示。深度不连续的边特征往往不那么可靠。</li>
<li>深度连续边特征的提取方法如图5所示。<ol>
<li>将点云划分为小voxel</li>
<li>对每个voxel内的点，使用RANSEC拟合若干平面，对每一对平面寻找其交线</li>
</ol>
</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2103.01627.pdf">https://arxiv.org/pdf/2103.01627.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/hku-mars/livox_camera_calib">https://github.com/hku-mars/livox_camera_calib</a></p>
<img src="/2021/05/01/0501/1.png" class>
<img src="/2021/05/01/0501/2.png" class>
<img src="/2021/05/01/0501/3.png" class>
<img src="/2021/05/01/0501/4.png" class>
<img src="/2021/05/01/0501/5.png" class>
<img src="/2021/05/01/0501/6.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
        <tag>visual</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title>0503 Towards High-Performance Solid-State-LiDAR-Inertial Odometry and Mapping</title>
    <url>/2021/05/03/0503/</url>
    <content><![CDATA[<p><em>作者:Kailai Li, Meng Li, and Uwe D. Hanebeck</em><br><em>机构:KIT</em><br><em>发表:RA-L</em></p>
<p><strong>Abstract</strong><br>我们提出了一种新的紧耦合的，对固态激光雷达和机械式雷达都适用的雷达惯导SLAM框架。前端包含一个轻量级的雷达里程计进行快速的关键帧之间的运动估计；后端是一个使用边缘化方法与滑动窗口，基于关键帧的，分层优化，来融合IMU和雷达的数据。对于Livox-Horizon（一款固态激光雷达），提出了一种新的特征点提取的方法来应对预处理时的不规律扫描。LiLi-OM是一个实时可以达到超过SOTA精度的系统。</p>
<span id="more"></span>

<p><strong>主要贡献：</strong></p>
<ol>
<li>提出了一个紧耦合的雷达惯导系统；</li>
<li>一种针对Livox Horizon的特征提取方法(与LOAM差不多，使用特征值来判断）；</li>
<li>一个使用边缘化方法与滑动窗口，基于关键帧的，分层优化方法；</li>
<li>进行了实际实验。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2010.13150.pdf">https://arxiv.org/pdf/2010.13150.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/KIT-ISAS/lili-om">https://github.com/KIT-ISAS/lili-om</a></p>
<img src="/2021/05/03/0503/1.png" class>
<img src="/2021/05/03/0503/2.png" class>
<img src="/2021/05/03/0503/3.png" class>
<img src="/2021/05/03/0503/4.png" class>
<img src="/2021/05/03/0503/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>solid</tag>
        <tag>IMU</tag>
      </tags>
  </entry>
  <entry>
    <title>0502 Multi-Robot Distributed Semantic Mapping in Unfamiliar Environments through Online Matching of Learned Representations</title>
    <url>/2021/05/02/0502/</url>
    <content><![CDATA[<p>*作者:*Stewart Jamieson , Kaveh Fathian , Kasra Khosoussi , Jonathan P. How  , Yogesh Girdhar<br>*机构:*MIT+WHOI（伍兹霍尔海洋研究所）<br>*发表:*ICRA 2021</p>
<p><strong>Abstract</strong><br>我们提出了一种分布式多机器人在未知环境中的语义建图系统。大多数SOTA语义建图系统一般基于监督学习算法，这样不能实时给新观察到的物体进行分类。非监督学习算法可以基于新观察的物体类别，但是由于多机器人的独立性，对于同一种事物往往不能获得一个一致性的标签。这种问题会随着机器人数量的增加而更加严重，这不利于各个机器人产生的局部地图的融合。我们提出的算法克服了这些缺点：使每个机器人使用非监督学习算法来进行语义分类。同时使用一个多路匹配算法，来获得不同机器人对同一类事物标签的一致性。与SOTA相比，我们的建图效果有20%-60%的提升，而且不会随着机器人数量的增多而下降。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>本文主要关注海底场景。该场景的特点是：大型未知场景（所以需要多机器人）；容易出现新物种或者新的地质现象；</li>
<li>匹配算法如图二所示。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2103.14805.pdf">https://arxiv.org/pdf/2103.14805.pdf</a><br><strong>开源代码：</strong><a href="https://gitlab.com/warplab/ros/sunshine">https://gitlab.com/warplab/ros/sunshine</a></p>
<img src="/2021/05/02/0502/1.png" class>
<img src="/2021/05/02/0502/2.png" class>
<img src="/2021/05/02/0502/3.png" class>]]></content>
      <tags>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>0504 MLOD:Awareness of Extrinsic Perturbation in Multi-LiDAR 3D Object Detection for Autonomous Driving</title>
    <url>/2021/05/05/0504/</url>
    <content><![CDATA[<p><em>作者:Jianhao Jiao ∗ , Peng Yun ∗ , Lei Tai, Ming Liu</em><br><em>机构:HKUST</em><br><em>发表:IROS 2020</em></p>
<p>注：接下来三天会介绍HKUST的一个实验室关于多激光雷达的三项工作，分别发表在IROS2020， ICRA2021， TRO2021，本篇为多激光雷达在3D目标检测中的使用问题。</p>
<p><strong>Abstract</strong><br>在多传感器系统中，外参的扰动（比如震动，温度导致的漂移，标定误差等）总会存在（如图1）。在本篇文章中，我们关注了这种外参的不确定因素在多激光雷达3D目标检测任务中的影响。我们首先分析了外参扰动对两个简单几何任务的影响。为了最小化有害的影响，我们将不确定因素传播给了每一个输入的点云，然后使用这个信息来改进3D几何任务的方法。随后我们扩展了我们的发现，提出了一个3D目标检测的网络——MLOD。MLOD是一个两阶段的网络，在第一个阶段融合多个雷达的信息，并在第二个极端处理外参的扰动。最后我们进行了真实的实验。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>文章尝试了三种融合方案：分别在输入，特征，输出阶段，执行LiDAR的融合；</li>
<li>文章对外参的不确定性与模型的测量误差一起进行建模；</li>
<li>使用SECOND来生成3D proposals。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>分析了外参扰动对多雷达几何任务的影响，并证明了输入不确定性的先验可以提高对这种影响的鲁棒性；</li>
<li>我们提出了一种两阶段的3D目标检测方法；</li>
<li>进行了实际实验。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2010.11702.pdf">https://arxiv.org/pdf/2010.11702.pdf</a><br><strong>开源代码：</strong><a href="https://ram-lab.com/file/site/mlod">https://ram-lab.com/file/site/mlod</a></p>
<img src="/2021/05/05/0504/1.png" class>
<img src="/2021/05/05/0504/2.png" class>
<img src="/2021/05/05/0504/3.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>multi</tag>
      </tags>
  </entry>
  <entry>
    <title>0505 Greedy-Based Feature Selection for Efficient LiDAR SLAM</title>
    <url>/2021/05/05/0505/</url>
    <content><![CDATA[<p><em>作者:Jianhao Jiao, Yilong Zhu, Haoyang Ye, Huaiyang Huang, Peng Yun, Linxin Jiang, Lujia Wang, Ming Liu</em><br><em>机构:HKUST</em><br><em>发表:ICRA 2021</em></p>
<p>注：多激光雷达（2/3），本篇关注激光SLAM中提取到特征点的选择问题。</p>
<p><strong>Abstract</strong><br>激光SLAM在大规模真实场景下，虽然可以达到很好的结果，但是一般都会有很高的延迟（因为点云配准和非线性优化）。本文证明了选择特征的一个子集对激光SLAM系统准确性和延迟都有积极的作用。我们将特征选择（feature selection，不是feature extraction）表示为一个组合优化问题，在数量约束的前提下保持信息矩阵的spectral属性。使用随机贪婪算法来实时估计最优解。为了避免坏估计，我们还提出了一个评价环境是否退化的策略，来实时修改特征的数量。提出的方法还被用到了多激光雷达SLAM系统（M-LOAM-gf）。最后进行了真实的实验.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>文章关注如何选择“good feature”，这种特征定义为：对位姿估计最有用的特征。具体算法见图1；</li>
<li>使用lamda来评价环境，lamda定义见图2；</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>我们将好特征选择的问题转化为保持信息矩阵谱属性的问题，谱属性定义为矩阵的特征值；</li>
<li>将提出的算法与多激光SLAM系统相融合，并提出了如何评价环境退化的方法和自适应调整特征数量的方法；</li>
<li>进行了实际实验。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://www.ram-lab.com/papers/2021/jiao2021greedy.pdf">https://www.ram-lab.com/papers/2021/jiao2021greedy.pdf</a><br><strong>开源代码：</strong><a href="https://ram-lab.com/file/site/m-loam">https://ram-lab.com/file/site/m-loam</a></p>
<img src="/2021/05/05/0505/1.png" class>
<img src="/2021/05/05/0505/2.png" class>
<img src="/2021/05/05/0505/3.png" class>
<img src="/2021/05/05/0505/4.png" class>
<img src="/2021/05/05/0505/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
        <tag>multi</tag>
      </tags>
  </entry>
  <entry>
    <title>0506 Robust Odometry and Mapping for Multi-LiDAR Systems with Online Extrinsic Calibration</title>
    <url>/2021/05/06/0506/</url>
    <content><![CDATA[<p><em>作者:Jianhao Jiao, Haoyang Ye, Yilong Zhu, and Ming Liu</em><br><em>机构:HKUST</em><br><em>发表:T-RO 2021</em></p>
<p><strong>Abstract</strong><br>结合多个激光雷达可以使机器人最大化它对环境的感知能力。本篇文章提出了一个系统实现了鲁棒且实时的多激光雷达的外参标定，里程计和建图。我们的方法包含以下步骤：</p>
<ol>
<li>从原数据提取边特征面特征（数据预处理）；</li>
<li>运动估计和外参标定的初始化，随后一个基于滑动窗口的多雷达里程计，伴随着实时外参标定和收敛性判断。</li>
<li>我们开发了一个建图算法来构建全局地图，并且使用scan-to-map的方式优化位姿并减少不确定性。</li>
</ol>
<p>我们在10个序列上评估了标定和SLAM的结果，并和SOTA做对比。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>整个流程如图1所示，分为如下几个模块:数据预处理，初始化，雷达里程计，建图</li>
<li>数据预处理所做的事情：点云分割（聚类），提取边特征面特征（与LOAM一样）；</li>
<li>初始化所做的事情：<ol>
<li>雷达里程计（scan-to-scan，与LOAM的不同为:对边特征的处理,LOAM中计算边特征的残差为点到边的距离，这里修改为点到相交出这条线的两个面的距离的一个向量，这样的好处是1.提供了更多的约束；2.是向量，可以乘协方差矩阵）</li>
<li>外参标定：通过对齐其两个雷达的运动序列来获得初始值</li>
</ol>
</li>
<li>基于滑动窗口的雷达里程计所做的事情：<ol>
<li>将点云地图分为三部分，如图3：base-LiDAR产生的前X1-Xp，Xp+1到XN+1,其他雷达生成的；</li>
<li>对第一部分视作不动的，第二部分在优化中还要继续优化，第三部分根据标定的收敛性判断如何使用；</li>
<li>边缘化方法来更新滑动窗口</li>
</ol>
</li>
<li>可抛弃不确定性高的点的建图模块：<ol>
<li>不确定性有以下几种情况：退化的位姿估计，外参扰动</li>
<li>这一部分看起来与前天介绍的第一篇有些类似，对不确定性进行建模。</li>
</ol>
</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>自动初始化，计算外参以及计算位姿变化。</li>
<li>完全不需要外部介入的标定方法；</li>
<li>基于滑动窗口的里程计方法；</li>
<li>一个两阶段的构建地图方法，可以将地图中不确定性高的噪点去除。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2010.14294.pdf">https://arxiv.org/pdf/2010.14294.pdf</a><br><strong>开源代码：</strong><a href="https://ram-lab.com/file/site/m-loam">https://ram-lab.com/file/site/m-loam</a></p>
<img src="/2021/05/06/0506/1.png" class>
<img src="/2021/05/06/0506/2.png" class>
<img src="/2021/05/06/0506/3.png" class>
<img src="/2021/05/06/0506/4.png" class>
<img src="/2021/05/06/0506/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>calibration</tag>
        <tag>multi</tag>
      </tags>
  </entry>
  <entry>
    <title>0507 3D Surfel Map-Aided Visual Relocalization with Learned Descriptors</title>
    <url>/2021/05/07/0507/</url>
    <content><![CDATA[<p><em>作者:Haoyang Ye, Huaiyang Huang, Marco Hutter, Timothy Sandy, and Ming Liu</em><br><em>机构:HKUST</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>在本篇文章中，我们介绍了一种视觉重定位的方法，使用3Dsurfel地图的几何信息。首先我们对3D surfel地图进行全局索引，以构建一个数据库来将图像点和surfel地图相对应。利用Surfel重投影约束来优化数据库中的关键帧位姿和地图点。 然后，分层次的相机重新定位算法利用数据库来估计6自由度的相机位姿。 学习得到的descriptor（指super point）可进一步用来提高在具有挑战性的场景下的性能。 最后，进行了实际实验。</p>
<span id="more"></span>

<p><strong>论文地址：</strong><a href="https://www.ram-lab.com/papers/2021/ye2021icra.pdf">https://www.ram-lab.com/papers/2021/ye2021icra.pdf</a></p>
<img src="/2021/05/07/0507/1.png" class>
<img src="/2021/05/07/0507/2.png" class>
<img src="/2021/05/07/0507/3.png" class>
<img src="/2021/05/07/0507/4.png" class>
<img src="/2021/05/07/0507/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>visual</tag>
        <tag>relocalization</tag>
        <tag>surfel</tag>
      </tags>
  </entry>
  <entry>
    <title>0508 Dynamic SLAM:The Need For Speed</title>
    <url>/2021/05/08/0508/</url>
    <content><![CDATA[<p><em>作者:Mina Henein, Jun Zhang, Robert Mahony and Viorela Ila</em><br><em>机构:Australian National University（ANU）</em><br><em>发表:ICRA 2020</em></p>
<p><strong>Abstract</strong><br>SLAM问题通常假设环境是静止的，但实际情况却是动态的环境，这要求识别动态物体并估计他们的速度。现有的大多数解决此问题的SLAM方法通常依赖3D物体的模型数据库，或施加明显的运动约束。在这篇文章中，我们提出了一个基于特征的，使用语义分割的，不需要运动物体模型的，可以识别并估计动态物体运动的SLAM系统。该算法可以生成一个既包含动态物体又包含静态物体的地图，并且可以获得动态物体的速度。</p>
<span id="more"></span>
<p><strong>一些信息：</strong><br>文章主要使用了因子图的方法，对动态物体也进行约束，如图2和图3所示；图3的第一行第二行和第三行分别对应图二中的黄色因子，蓝色因子，橙色因子，分别描述对特征点观测的约束，自身位姿变化的约束，和动态物体移动的约束。</p>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2002.08584.pdf">https://arxiv.org/pdf/2002.08584.pdf</a></p>
<img src="/2021/05/08/0508/1.png" class>
<img src="/2021/05/08/0508/2.png" class>
<img src="/2021/05/08/0508/3.png" class>
<img src="/2021/05/08/0508/4.png" class>
<img src="/2021/05/08/0508/5.png" class>
<img src="/2021/05/08/0508/6.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>dynamic</tag>
        <tag>每日论文分享</tag>
        <tag>vslam</tag>
      </tags>
  </entry>
  <entry>
    <title>0509 ERASOR:Egocentric Ratio of Pseudo Occupancy-based Dynamic Object Removal for Static 3D Point Cloud Map Building</title>
    <url>/2021/05/09/0509/</url>
    <content><![CDATA[<p><em>作者:Hyungtae Lim, Sungwon Hwang, and Hyun Myung</em><br><em>机构:KAIST(韩科院）</em><br><em>发表:ICRA 2021</em></p>
<p>注：昨天带来了一篇视觉SLAM处理动态物体的文章，今天再带来一篇类似目标的激光SLAM的文章。<br><strong>Abstract</strong><br>在城市环境中，雷达的扫描通常会包含静态物体。但是，构建3D点云地图时，动态物体通常会在地图中留下不想要的轨迹（由于地图构建是点云堆叠起来的）。这些动态物体的轨迹会被当成障碍物，对导航和定位产生了不好的影响。为了处理这种问题，本篇文章提出了一个新的静态地图构建的方法，称为ERASOR，很快很鲁棒。我们的方法注意到大多数的动态物体是不可避免地接触地面的。根据这一点，我们提出了一个新概念称作伪占据（pseudo occupancy），来表示单位空间被占据，但没有完全占据（可以发生变化）。最后，使用分区域的地平面拟合方法（R-GPF）来将盛有动态点的bin中的静态点挑出来。在SegmanticKITTI中进行了实验，超过了SOTA。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>文章将动态物体去除的方法分为了两类：在生成地图时去除，和在获得地图后再删去。后一种方法又分为三类：基于segmentation的，基于ray tracing的，基于 visibility的（后两种方法的缺陷如图1所示）。本文的方法为后者，即生成地图之后再去除。</li>
<li>描述伪占据这一概念，文章采用一帧点云和建好的地图中的同一个区域，里面点的max_z - min_z， 然后用这两个数的比值来判断是否有动态物体。如图3所示。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>提出了一种快速鲁棒的方法，称作Scan Ratio Test（SRT）来获取包含动态点的bin；</li>
<li>获得bin后，使用R-GRF来取出bin中的静态点（地面点）；</li>
<li>提出了去除动态物体的定量评价标准：保留率和去除率.</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2103.04316.pdf">https://arxiv.org/pdf/2103.04316.pdf</a></p>
<img src="/2021/05/09/0509/1.png" class>
<img src="/2021/05/09/0509/2.png" class>
<img src="/2021/05/09/0509/3.png" class>
<img src="/2021/05/09/0509/4.png" class>
<img src="/2021/05/09/0509/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>dynamic</tag>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
      </tags>
  </entry>
  <entry>
    <title>0511 GOSMatch:Graph-of-Semantics Matching for Detecting Loop Closures in 3D LiDAR data</title>
    <url>/2021/05/11/0511/</url>
    <content><![CDATA[<p><em>作者:Yachen Zhu, Yanyang Ma, Long Chen, Cong Liu, Maosheng Ye, and Lingxi Li</em><br><em>机构:SYSU</em><br><em>发表:IROS 2020</em></p>
<p><strong>Abstract</strong><br>针对闭环检测任务，point-level的方法一般不是很稳定。本文提出了一种semantic-level的方法：GOSMatch，来提供更可靠的重定位。我们利用一种新的从语义对象的空间关系中生成的描述子，来描述数据并进行数据匹配。我们还提出了一种由粗到细的策略，来高效的搜索闭环。除此之外，在检测到闭环之后GOSMatch可以输出一个准确的6自由度的初始位姿估计。最后，在KITTI上进行了实验。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>语义分割使用rangenet++；</li>
<li>题目中graph of semantic的含义为，将物体作为节点，分为三类（树，车辆，电线杆）；边分为六类（车车，树树，杆杆，车树，树杆，杆车）；（见图1）</li>
<li>全局描述子（graph descriptor）为上述六种边组成的直方图。比如A类边，长度范围是[l_min,l_max],将其分为b个区间，每个区间长度为（l_max - l_min）/b, 统计落在这个区间的边的个数。（见图1）</li>
<li>局部描述子（vertex descriptors）也是直方图，不过是对一个点所连的边进行描述。（见图1）</li>
</ol>
<p><strong>主要贡献：</strong><br>1.一个物体级的方法来进行重定位；<br>2.一种基于物体空间位置的全局描述子和局部描述子，可以进行两步分层搜索.</p>
<p><strong>论文地址：</strong><a href="https://ieeexplore.ieee.org/document/9341299/">https://ieeexplore.ieee.org/document/9341299/</a><br><strong>开源代码：</strong><a href="https://github.com/zhuyachen/GOSMatch%EF%BC%88matlab%E5%AE%9E%E7%8E%B0%EF%BC%89">https://github.com/zhuyachen/GOSMatch（matlab实现）</a></p>
<img src="/2021/05/11/0511/1.png" class>
<img src="/2021/05/11/0511/2.png" class>
<img src="/2021/05/11/0511/3.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>semantic</tag>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
      </tags>
  </entry>
  <entry>
    <title>0510 Distributed Client-Server Optimization for SLAM with Limited On-Device Resources</title>
    <url>/2021/05/10/0510/</url>
    <content><![CDATA[<p><em>作者:Yetong Zhang, Ming Hsiao, Yipu Zhao, Jing Dong, and Jakob J. Enge</em><br><em>机构:Facebook Reality Labs Research</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>一些设备无法负担运行一个完整的SLAM系统所需要的计算和存储的开销。我们提出了一个client-server结构的SLAM优化框架，可以在低性能的设备（client）上进行实时的状态估计。client只在一小部分地图上进行工作，地图的其他部分由server进行处理。通过发送总结好的剩余部分的地图信息给client，状态估计将会更加精准。更进一步提高精度的方法是“早闭环检测（early loop closure）”，可以使client从server读取有用的信息。实验证明了在计算力和存储受限的设备上，可以达到准确的估计。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>ORB-SLAM需要200MB内存，但一些嵌入式设备只有1MB RAM；</li>
<li>解决的两个问题<ol>
<li>估计状态的上限取决于client已知的local graph信息；</li>
<li>server给出全局优化需要时间，这导致client不能实时地利用到这个信息。</li>
</ol>
</li>
<li>算法流程：server定期将总结好的历史信息发送给client；server将与新变量相关的历史变量发到client上，这样可以实现“早闭环”；第一步中汇总的信息进行稀疏化，来减小通信开销</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2103.14303.pdf">https://arxiv.org/pdf/2103.14303.pdf</a></p>
<img src="/2021/05/10/0510/1.png" class>
<img src="/2021/05/10/0510/2.png" class>
<img src="/2021/05/10/0510/3.png" class>
<img src="/2021/05/10/0510/4.png" class>
<img src="/2021/05/10/0510/5.png" class>
<img src="/2021/05/10/0510/6.png" class>
<img src="/2021/05/10/0510/7.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>distribute</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title>0514 HD Map Update for Autonomous Driving With Crowdsourced Data</title>
    <url>/2021/05/14/0514/</url>
    <content><![CDATA[<p><em>作者:Kitae Kim , Soohyun Cho, and Woojin Chung</em><br><em>机构:Korea University</em><br><em>发表:ICRA 2021 RA-L 2021</em></p>
<p><strong>Abstract</strong><br>自动驾驶汽车使用高精度地图(HD map)可以进行准确的定位，并且生成不碰撞的轨迹。因此,保持高精度地图的准确性很重要。通常，HD map的构建要使用昂贵的地图构建系统，而且要进行很多人工的修改。传统的HD map因为太过昂贵，而不能时常进行构建。在本文中，我们使用了低成本众包传感器收集的道路数据，这些传感器被安装在反复移动的车（比如公交）上。我们提出了一种维护HD map的方法，关注数据中的landmark信息，选择不确定度低的数据来更新地图。并考虑离散和连续地标（交通灯交通标志，车道线）的差异，设计一个观察学习算法。通过所提出的更新模式选择策略，可以调整地图更新的触发条件。本文所提出的地图更新方案已通过从真实道路环境中收集的众包数据进行了实验验证.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>传感器使用的是摄像头和GNSS；</li>
<li>文章主要提出了一种车道线检测的方法；并且针对离散的地标如交通灯，和连续的地标如车道线，分别给出了更新HD map的策略。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://ieeexplore.ieee.org/document/9357917">https://ieeexplore.ieee.org/document/9357917</a></p>
<img src="/2021/05/14/0514/1.png" class>
<img src="/2021/05/14/0514/2.png" class>
<img src="/2021/05/14/0514/3.png" class>
<img src="/2021/05/14/0514/4.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title>0517 LAMP:Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments</title>
    <url>/2021/05/17/0515/</url>
    <content><![CDATA[<p><em>作者:Kamak Ebadi, Yun Chang, Matteo Palieri, Alex Stephens, Alex Hatteland, Eric Heiden, Abhishek Thakur, Benjamin Morrell, Sally Wood, Luca Carlone, Ali-akbar Agha-mohammadi</em><br><em>机构:CIT+MIT</em><br><em>发表:ICRA 2020</em></p>
<p><strong>Abstract</strong><br>在未知复杂的地下环境（例如矿洞）中进行SLAM是一件困难的任务。困难如下：</p>
<ol>
<li>传感器必须在非标称的环境（光照差，充满灰尘水坑等环境）下工作；</li>
<li>地面不平坦并且湿滑，使车轮里程计不准；</li>
<li>没有明显的特征的长廊容易导致漂移；</li>
<li>例如隧道和矿石等具有重复外观的环境，容易导致错误的闭环检测，从而使整个地图严重变形。<br>本文描述了一个在DARPA地下挑战赛中的，基于激光雷达的SLAM系统。提出了一个更适合地下场景的多机器人SLAM架构，包含一个精准的前端，以及可拒绝虚假闭环的鲁棒后端。<span id="more"></span></li>
</ol>
<p><strong>一些信息：</strong></p>
<ol>
<li>机器人与基站之间传输的信息包含：位姿图，机器人位姿，点云（如图1所示）；</li>
<li>文章提出的拒绝虚假闭环的方法称为ICM（增量一致测量集最大化算法）。分三步进行：检验沿着路径的位姿变化与闭环检测到的位姿变化的差距（如图2,x1-&gt;x2-&gt;..x6 与LC；成对一致性检验，检验两个闭环之间是否一致；为一致的闭环构建邻接矩阵，寻找其中的最大团，其余的闭环将被拒绝。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>描述了一个多机器人的系统架构；</li>
<li>对现有slam算法进行改进：<ol>
<li>基于scan-to-scan和scan-to-submap的前端；</li>
<li>可以融合多个传感器数据和操作员输入的后端；</li>
<li>使用增量一致性测量设置最大值的方法来拒绝错误的闭环检测。</li>
</ol>
</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2003.01744v2.pdf">https://arxiv.org/pdf/2003.01744v2.pdf</a></p>
<img src="/2021/05/17/0515/1.png" class>
<img src="/2021/05/17/0515/2.png" class>
<img src="/2021/05/17/0515/3.png" class>
<img src="/2021/05/17/0515/4.png" class>
<img src="/2021/05/17/0515/5.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>multi</tag>
      </tags>
  </entry>
  <entry>
    <title>0516 Place Recognition in Forests With Urquhart Tessellations</title>
    <url>/2021/05/17/0516/</url>
    <content><![CDATA[<p><em>作者:Guilherme V. Nardari, Avraham Cohen, Steven W. Chen, Xu Liu, Vaibhav Arcot, Roseli A. F. Romero, and Vijay Kumar</em><br><em>机构:University of São Paulo + University of Pennsylvania</em><br><em>发表:ICRA 2021 RA-L 2021</em></p>
<p><strong>Abstract</strong><br>在本文中，我们提出了一个基于Urquhart 镶嵌的新的描述子，由森林中树的位置衍生出来的。我们提出一个框架使用这种描述子，在重叠和噪声影响下进行重定位。我们在仿真和真实场景中的松树林进行了无人机上的闭环检测实验，展现了我们的鲁棒性和准确度。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>森林中进行重定位的难点：GPS不可用，区域很广；场景很重复，landmark都是一样的，唯一的区别是其在地图中的位置不同；</li>
<li>解决办法为用图的形式表示这种场景，图的节点为landmark，点之间的连线可以组成一个个的多边形；</li>
<li>题目中tessellation的意思为：一组没有间隔且没有重叠，可以覆盖一个凸包的多边形；</li>
<li>提取多层次的描述子：1.使用所有边 2.使用Delaunay triangulation划分后的三角形的边 3.Urquhart tessellation后的边。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>提出一种新的描述子，能够处理大规模的重复环境，并且对噪声很鲁棒；</li>
<li>一个利用上述描述子进行重定位的框架。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://ieeexplore.ieee.org/document/9264665/">https://ieeexplore.ieee.org/document/9264665/</a></p>
<img src="/2021/05/17/0516/1.png" class>
<img src="/2021/05/17/0516/2.png" class>
<img src="/2021/05/17/0516/3.png" class>
<img src="/2021/05/17/0516/4.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>localization</tag>
      </tags>
  </entry>
  <entry>
    <title>0518 RadarLoc:Learning to Relocalize in FMCW Radar</title>
    <url>/2021/05/18/0518/</url>
    <content><![CDATA[<p><em>作者:Wei Wang, Pedro P. B. de Gusmão, Bo Yang, Andrew Markham, and Niki Trigoni</em><br><em>机构:Oxford</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>学习的方法还没有被应用在毫米波雷达的数据上。在本文中，我们研究了如何使用深度学习的方法来预测毫米波雷达的全局位姿。特别的我们提出了一个端到端的包含self-attention的神经网络来预测6DOF位姿。我们也提出了通过几何约束来提高定位精度的方法。我们在 Oxford Radar RobotCar数据集上进行了实验，证明了我们的方法比基于毫米波雷达的方法和基于深度相机的方法更有效。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>整个网络分为3个模块：self-attention模块，encoder模块，和deep pose regressor模块；</li>
<li>毫米波雷达的原始数据首先被转化为笛卡尔坐标系下的鸟瞰图；</li>
<li>self-attention用来减少自身噪音和动态物体的影响；</li>
<li>encoder模块使用DenseNet来提取特征；</li>
<li>deep pose regressor使用带有两个分支的MLP，分别产生平移和旋转的参数。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>证明了毫米波雷达也能以端到端的形式来估计位姿；</li>
<li>使用几何约束来优化位姿估计的效果。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2103.11562.pdf">https://arxiv.org/pdf/2103.11562.pdf</a></p>
<img src="/2021/05/18/0518/1.png" class>
<img src="/2021/05/18/0518/2.png" class>
<img src="/2021/05/18/0518/3.png" class>
<img src="/2021/05/18/0518/4.png" class>
<img src="/2021/05/18/0518/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>localization</tag>
        <tag>radar</tag>
      </tags>
  </entry>
  <entry>
    <title>0519 BALM:Bundle Adjustment for Lidar Mapping</title>
    <url>/2021/05/19/0519/</url>
    <content><![CDATA[<p><em>作者:Zheng Liu and Fu Zhang</em><br><em>机构:HKU</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>在关键帧的滑动窗口上进行BA在视觉SLAM里面十分流行，并且可以有效降低漂移误差。但是在激光SLAM中，BA几乎没有被使用过，这是因为点云的特征十分稀疏，不是很好找到其对应关系。在本文中，我们将激光BA问题定义为最小化点到其对应边或面的距离。不像视觉SLAM中，BA问题得同时求解位姿和特征点的位置，在激光SLAM中可以将求解特征点的位置从BA问题中去除，这减小了优化的搜索空间。为了提高优化速度，我们以闭式解的方式求得边特征与面特征，并将cost function进行2阶求导。除此之外，我们还提出了一种新的自适应体素方法来更高效的寻找特征对应关系。提出的方法被融合进了LOAM，被实验证明有效。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>BA问题的数学表达式如图6所示</li>
<li>自适应划分的好处如下：与八叉树的数据结构很契合；当平面或边缘较大时，这种方式会比对所有特征点建KD-Tree更有效；可以减小搜索匹配的时间。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2010.08215.pdf">https://arxiv.org/pdf/2010.08215.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/hku-mars/BALM">https://github.com/hku-mars/BALM</a></p>
<img src="/2021/05/19/0519/1.png" class>
<img src="/2021/05/19/0519/2.png" class>
<img src="/2021/05/19/0519/3.png" class>
<img src="/2021/05/19/0519/4.png" class>
<img src="/2021/05/19/0519/5.png" class>
<img src="/2021/05/19/0519/6.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>code</tag>
        <tag>LiDAR</tag>
      </tags>
  </entry>
  <entry>
    <title>0522 DOT:Dynamic Object Tracking for Visual SLAM</title>
    <url>/2021/05/22/0522/</url>
    <content><![CDATA[<p><em>作者:Irene Ballester, Alejandro Fontan, Javier Civera, Klaus H. Strobl, Rudolph Triebel</em><br><em>机构:University of Zaragoza</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>在本篇文章中,我们提出了DOT(dynamic object tracking),一种可以加到已有的SLAM系统中的前端,来提高在动态场景中的准确性和稳定性.DOT结合了实例分割与多视角集合,来生成动态物体的mask,从而在优化的过程中避免这些区域的影响.<br>为了判断哪些物体确实处于运动状态,DOT首先分割了所有可能移动的物体,随后通过最小化重投影误差来跟踪这些物体.这种短时间内的追踪提高了分割的准确度.最后,真正的动态物体的mask被生成.我们将DOT集成在ORB SLAM2中,并在3个数据集中进行了测试.实验展示了效果.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>1.本篇文章,在实现思路上与2021.05.01分享的Towards Real-time Semantic RGB-D SLAM in Dynamic Environments在实现思路上有着一些相似之处.</li>
<li>本文使用的语义分割网络为Detectron2(<a href="https://github.com/facebookresearch/detectron2">https://github.com/facebookresearch/detectron2</a>)</li>
<li>文章在跟踪动态物体时,提出了一些方法来减少遮挡,光照变化和分割误差对追踪的影响,详情见3.4节.</li>
<li>判断物体是否移动,文章提出了一个评价指标disparity,如图五.</li>
<li>最终的mask有两种来源:从上一帧通过追踪得到的,和从网络里新得到的.</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2010.00052.pdf">https://arxiv.org/pdf/2010.00052.pdf</a></p>
<img src="/2021/05/22/0522/1.png" class>
<img src="/2021/05/22/0522/2.png" class>
<img src="/2021/05/22/0522/3.png" class>
<img src="/2021/05/22/0522/4.png" class>
<img src="/2021/05/22/0522/5.png" class>
<img src="/2021/05/22/0522/6.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>dynamic</tag>
        <tag>每日论文分享</tag>
        <tag>visual</tag>
      </tags>
  </entry>
  <entry>
    <title>0523 Monocular Camera Localization in Prior LiDAR Maps with 2D-3D Line Correspondences</title>
    <url>/2021/05/23/0523/</url>
    <content><![CDATA[<p><em>作者:Huai Yu1, Weikun Zhen, Wen Yang, Ji Zhang and Sebastian Scherer</em><br><em>机构:武大+CMU</em><br><em>发表:IROS 2020</em></p>
<p><strong>Abstract</strong><br>使用相机在已有地图中进行定位是基于视觉导航的基础。目前，VO和VIO在状态估计方面已经发展地很好了，但是在闭环检测时会发生不可避免的位姿跳变（由于累计误差）（这对导航来说有副作用）。为了避免这个问题，我们利用2D-3D中线特征的对应关系，提出了一种在LiDAR地图中使用单目摄像头进行重定位的方法。为了处理激光点云和图像之间的差异，我们offline地从LiDAR地图中提取3D线条，并online地从图像序列中提取2D线条。有了VIO输出的对位姿的预测，我们可以高效地，获得2D-3D中线的粗糙的对应关系。随后，相机的位姿和对应关系可以通过最小化投影误差来迭代优化。最后，我们在EurocMav数据集上进行了实验，证明了提出的方法可以使估计相机位姿时，没有累计误差，并且没有位姿跳变。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>具体流程图见图2.使用PnP来初始化，使用VINS-Mono来做位姿估计；</li>
<li>2D线特征提取，见图3。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2004.00740.pdf">https://arxiv.org/pdf/2004.00740.pdf</a></p>
<img src="/2021/05/23/0523/1.png" class>
<img src="/2021/05/23/0523/2.png" class>
<img src="/2021/05/23/0523/3.png" class>
<img src="/2021/05/23/0523/4.png" class>
<img src="/2021/05/23/0523/5.png" class>
<img src="/2021/05/23/0523/6.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>visual</tag>
        <tag>localization</tag>
      </tags>
  </entry>
  <entry>
    <title>0524 Extrinsic Calibration of Multiple LiDARs of Small FoV in Targetless Environments</title>
    <url>/2021/05/24/0524/</url>
    <content><![CDATA[<p><em>作者:Xiyuan Liu and Fu Zhang</em><br><em>机构:HKU</em><br><em>发表:RA-L 2021 ICRA 2021</em></p>
<p><strong>Abstract</strong><br>使用多个小视场（FoV）的固态激光雷达拼接在一起可以实现类似机械式旋转雷达的效果。但是由于视场都很小，我们或者需要额外的传感器进行校准，或者使它们的FoV产生重叠，来进行雷达之间外参的标定。为了克服这些限制，我们研发了一种不需要标定板的标定方法，通过移动来实现FoV的重叠，并构造因子图来解决雷达位姿和外参之间的约束。通过求解这个图优化问题，我们提出的方法可以标定FoV很少重叠，甚至不重叠的雷达。与此同时，生成了一个全局一致的点云地图。在不同硬件配置上的实验，证明了该方法的准确性和鲁棒性。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>使用的特征仍然为主流的边特征和面特征，使用GICP来进行约束。使用同一特征，对不同时间，不同雷达产生约束，如图3所示。</li>
<li>对框图（图4）的说明：<ol>
<li>stage 1：计算位姿变化，为每个雷达开了一个LOAM。输出为位姿以及特征。</li>
<li>stage 2：首先优化base雷达的位姿，然后使用其产生的特征点构建一个地图；再将每个雷达与地图对其，从而得到外参。</li>
<li>stage3：迭代优化，保持位姿不变优化外参，保持外参不变优化位姿</li>
</ol>
</li>
</ol>
<p><strong>主要贡献：</strong><br>1.一个完整的多激光雷达标定的系统：数据收集，图构建，图优化。在数据采集过程中，人为地制造视野重叠。将运动引入整个系统：将系统（小车）在多个静止位姿摆放，以产生对位姿估计和激光雷达外参的约束。使用KDtree进行对应特征的搜索，并基于这种对应关系构建因子图。最后提出了一个多阶段图优化方法，可以同时估计外参和机器人位姿；<br>2.提出了一种评价外参标定结果的方法。</p>
<p><strong>论文地址：</strong><a href="https://ieeexplore.ieee.org/document/9361153">https://ieeexplore.ieee.org/document/9361153</a></p>
<img src="/2021/05/24/0524/1.png" class>
<img src="/2021/05/24/0524/2.png" class>
<img src="/2021/05/24/0524/3.png" class>
<img src="/2021/05/24/0524/4.png" class>
<img src="/2021/05/24/0524/5.png" class>
<img src="/2021/05/24/0524/6.png" class>
<img src="/2021/05/24/0524/7.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>solid</tag>
        <tag>calibration</tag>
      </tags>
  </entry>
  <entry>
    <title>0525 MonoPair:Monocular 3D Object Detection Using Pairwise Spatial Relationships</title>
    <url>/2021/05/25/0525/</url>
    <content><![CDATA[<p><em>作者:Yongjian Chen， Lei Tai， Kai Sun， Mingyang Li</em><br><em>机构:Alibaba</em><br><em>发表:CVPR 2020</em><br>注：本篇介绍的原因是，这是一篇在detection领域使用图优化（g2o）的论文。<br><strong>Abstract</strong><br>单目3D目标检测是自动驾驶的一个重要组成部分，也是一个极具挑战性的问题，特别是对于那些被遮挡只有部分可见的目标。大多数检测器将每个3D目标视为独立的训练对象，不可避免地导致了遮挡物体缺乏有用的信息。为了解决这个问题，我们提出了一种新的方法，通过考虑成对样本之间的关系来改进单目3D目标检测。这样，我们可以对部分遮挡目标与其相邻的目标之间的空间约束进行编码。具体的，提出的检测器进行目标位置和距相邻目标的3D距离的不确定感知预测，随后通过非线性最小二乘进行联合优化。最后，为了保证运行效率，将一阶段不确定性感知预测结构与后优化模块进行了专门的集成。实验表明，我们的方法在KITTI 3D目标检测的排行榜上，特别是对于难样本，获得了最好的性能，超过了SOTA。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>预测阶段分别给出两种预测框，2D的和3D的，网络图如图1所示；预测结果说明如图2所示；</li>
<li>一对物体之间如何建立约束详见图3，4，5；</li>
<li>本篇文章主要用图优化来综合优化一对物体之间的距离，和每个物体的位置；</li>
<li>图的定义：图的顶点为物体，边为两成对物体之间的距离。每一个顶点有三个属性（u, v ,z）(如图2中所示），u v 为3D边框中心投影在2D平面上的坐标，z为深度。更多的图优化的信息，详见图6，7；</li>
<li>信息矩阵由不确定度构成。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>通过利用成对物体之间的空间关系，设计了一个新的检测器，极大地提高了被遮挡物体的精度；</li>
<li>提出了一种三维目标检测的不确定性感知预测模块，和物体距物体的距离一起进行联合优化。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2003.00504.pdf">https://arxiv.org/pdf/2003.00504.pdf</a></p>
<img src="/2021/05/25/0525/1.png" class>
<img src="/2021/05/25/0525/2.png" class>
<img src="/2021/05/25/0525/3.png" class>
<img src="/2021/05/25/0525/4.png" class>
<img src="/2021/05/25/0525/5.png" class>
<img src="/2021/05/25/0525/6.png" class>
<img src="/2021/05/25/0525/7.png" class>
<img src="/2021/05/25/0525/8.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>visual</tag>
        <tag>detection</tag>
      </tags>
  </entry>
  <entry>
    <title>0527 MULLS:Versatile LiDAR SLAM via Multi-metric Linear Least Square</title>
    <url>/2021/05/29/0527/</url>
    <content><![CDATA[<p><em>作者: Yue Pan , Pengchuan Xiao, Yujie He, Zhenlei Shao  and Zesong Li</em><br><em>机构: ethz，HESAI</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>本文关注在自动驾驶场景的激光SLAM。我们提出了MULLS，一个高效，低漂移的通用激光SLAM系统。前端使用双阈值地面滤波和PCA，对点云进行了粗糙的分类（地面，立面，屋顶，立柱，横梁，顶点等）。随后利用提出的多度量线性最小二乘迭代最近点算法，进行scan-to-submap的配准。每一类中的点到点，点到线，点到面的误差被联合优化来估计位姿变化。静态特征点被添加到局部地图，来保持地图更新。在后端，使用历史submap进行分层位姿图优化，从而减小航位推算产生的漂移。我们采取了7种激光雷达，超过100k帧的数据集，进行了大量的实验。于此同时，在KITTI上，本文提出的方法目前排名第13.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>7种激光雷达为不同线数的机械式雷达，具体见图9；</li>
<li>题目中的通用指的是不依赖激光雷达的特性，不必把点云变成环或者深度图像的形式，这样可以保证不丢失信息；</li>
<li>配准分为两种：local 和 global。区别为前者需要提供良好的初值，以避免陷入局部最优，本文使用本文提出的MULLS-ICP；后者没有初值，文中提到的方法有RANSEC，分支定界法（BnB），TEASER等，本文使用TEASER。</li>
<li>特征提取见图2，误差度量见图3，4，前端后端框图见图5，图优化见图6，实验结果见图7，8。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>一个通用的激光SLAM系统；</li>
<li>一种高效的局部配准算法MULLS-ICP，实现了粗分类几何特征点的多种误差度量的线性最小二乘优化。</li>
</ol>
<p><strong>论文地址：</strong><a href="https://arxiv.org/pdf/2102.03771.pdf">https://arxiv.org/pdf/2102.03771.pdf</a><br><strong>开源代码：</strong><a href="https://github.com/YuePanEdward/MULLS">https://github.com/YuePanEdward/MULLS</a></p>
<img src="/2021/05/29/0527/1.png" class>
<img src="/2021/05/29/0527/2.png" class>
<img src="/2021/05/29/0527/3.png" class>
<img src="/2021/05/29/0527/4.png" class>
<img src="/2021/05/29/0527/5.png" class>
<img src="/2021/05/29/0527/6.png" class>
<img src="/2021/05/29/0527/7.png" class>
<img src="/2021/05/29/0527/8.png" class>
<img src="/2021/05/29/0527/9.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
      </tags>
  </entry>
  <entry>
    <title>0603：PHASER:a Robust and Correspondence-free Global Pointcloud Registration</title>
    <url>/2021/06/04/0603/</url>
    <content><![CDATA[<p><em>作者:Lukas Bernreiter, Lionel Ott, Juan Nieto, Roland Siegwart and Cesar Cadena</em><br><em>机构:ETHZ</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>我们提出了PHASER，一种不需要对应关系的激光雷达点云的全局配准，对于噪音，稀疏性和部分重叠都很鲁棒。我们的方法可以无缝地处理多模态信息，并且不依赖于关键点提取或者描述子等预处理模块。通过傅里叶分析，PHASER直接利用传感器的信号，将多通道频谱进行融合，并且计算6-DOF的位姿变换。我们的配准流程（见图2）从寻找最可能的旋转r开始，随后寻找最可能的平移t。对r和t的估计都会根据其潜在流形的概率分布而考虑其分布，例如r对应Bingham分布，t对应Gaussian分布。这进一步允许我们通过考虑r的周期性来表示其不确定性。我们在不同的数据集和不同的传感器上进行了验证，并与一些知名的配准算法进行对比。我们的结果展示PHASER可以在100ms内，达到2cm和0.5°的精度。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>文章将配准问题形式化为两片点云经过傅里叶分析后的对应关系，<br>空间(spatial)傅里叶分析如图1上所示，球面（Spherical）</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>对点云进行球面和空间傅里叶分解，分别估计点云的旋转和平移；</li>
<li>一种对任意输入模态的融合方法；</li>
<li>一种估计分别利用Bingham分布和Gaussian分布来估计球面不确定度和空间相关不确定度的方法。</li>
</ol>
<p><strong>论文地址：<a href="https://arxiv.org/pdf/2102.02767.pdf">https://arxiv.org/pdf/2102.02767.pdf</a></strong><br><strong>开源代码：</strong></p>
<img src="/2021/06/04/0603/1.png" class>
<img src="/2021/06/04/0603/2.png" class>
<img src="/2021/06/04/0603/3.png" class>
<img src="/2021/06/04/0603/4.png" class>
<img src="/2021/06/04/0603/5.png" class>
<img src="/2021/06/04/0603/6.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>registration</tag>
      </tags>
  </entry>
  <entry>
    <title>0605：LiTAMIN:LiDAR-based Tracking And MappINg by Stabilized ICP for Geometry Approximation with Normal Distributions</title>
    <url>/2021/06/06/0605/</url>
    <content><![CDATA[<p><em>作者:Masashi Yokozuka, Kenji Koide, Shuji Oishi and Atsuhiko Banno</em><br><em>机构:AIST（日本产业技术综合研究所）</em><br><em>发表:IROS 2020</em></p>
<p><strong>Abstract</strong><br>本文提出了一个高计算效率，准确性和鲁棒性的ICP算法，利用正态分布簇的局部近似几何。与之前基于正态分布的ICP方法(比如NDT和G-ICP)相比，我们的方法通过Frobenius范数和正则化协方差矩阵来标准化loss函数。以前的方法主要使用PCA，这些方法的计算代价更高。除此之外。我们的方法还减少了错误闭环检测的影响。实验结果表明我们的方法比SOTA更好（LOAM，LeGO-LOAM,hdl_graph_slam）.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>文章对ICP所做的改变包括：</li>
<li>不使用原始点云，而是减少了部分点云，使密度均匀；</li>
<li>提出了一个新的cost function，如图3；</li>
<li>在闭环检测中，将ICP较差的结果当做ourlier，从而减少闭环检测错误的影响。</li>
</ol>
<p><strong>论文地址：<a href="https://ieeexplore.ieee.org/document/9341341/">https://ieeexplore.ieee.org/document/9341341/</a></strong></p>
<img src="/2021/06/06/0605/1.png" class>
<img src="/2021/06/06/0605/2.png" class>
<img src="/2021/06/06/0605/3.png" class>
<img src="/2021/06/06/0605/4.png" class>
<img src="/2021/06/06/0605/5.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>registration</tag>
      </tags>
  </entry>
  <entry>
    <title>0606:LiTAMIN2:Ultra Light LiDAR-based SLAM using Geometric Approximation applied with KL-Divergence</title>
    <url>/2021/06/07/0606/</url>
    <content><![CDATA[<p><em>作者:Masashi Yokozuka, Kenji Koide, Shuji Oishi and Atsuhiko Banno</em><br><em>机构:AIST</em><br><em>发表:ICRA 2021</em></p>
<p>注：本篇文章为昨天文章的后续工作，在ICP上又做了一些改进，进一步提升了配准的效率，达到了500Hz-1000Hz。<br><strong>Abstract</strong><br>在本篇文章中，我们提出了一个500Hz-1000Hz的SLAM系统。提出的方法大量减少了配准所需点云的数量，并且使用了一种新的ICP度量方法在保证准确率的同时加速配准的过程。当点云数量减少的时候，使用ICP配准的准确率一般是下降的，因为ICP的原理是最小化点之间的距离。为了避免这个问题，本文将对称的KL散度引入到ICP的cost中，这反应了两个概率分布之间的不同。这个cost不仅包含了点之间的距离，还包含了两个分布之间的不同。在KITTI上的实验证明了我们的方法拥有很高的计算效率，并且有着与SOTA相似的精准度。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>本文主要将LiTAMIN中点到正态分布的匹配，扩展到分布到分布的匹配，考虑了两个分布之间形状的不同；</li>
<li>KL散度及对称KL散度见图4，5；</li>
<li>ICP的cost function见图6，7；</li>
<li>耗时见图8.</li>
</ol>
<p><strong>论文地址：<a href="https://arxiv.org/pdf/2103.00784.pdf">https://arxiv.org/pdf/2103.00784.pdf</a></strong><br><strong>开源代码：</strong></p>
<img src="/2021/06/07/0606/1.png" class>
<img src="/2021/06/07/0606/2.png" class>
<img src="/2021/06/07/0606/3.png" class>
<img src="/2021/06/07/0606/4.png" class>
<img src="/2021/06/07/0606/5.png" class>
<img src="/2021/06/07/0606/6.png" class>
<img src="/2021/06/07/0606/7.png" class>
<img src="/2021/06/07/0606/8.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>registraion</tag>
      </tags>
  </entry>
  <entry>
    <title>0607：Range Image-based LiDAR Localization for Autonomous Vehicles</title>
    <url>/2021/06/10/0607/</url>
    <content><![CDATA[<p>*作者:Xieyuanli Chen, Ignacio Vizzo, Thomas Läbe, Jens Behley, Cyrill *<br><em>机构:University of Bonn</em><br><em>发表:ICRA 2021</em></p>
<p><strong>Abstract</strong><br>在本文中，我们提出了利用激光生成的深度图来解决在大规模户外场景mesh地图中的定位问题。我们使用泊松表面重建来生成mesh地图。使用激光扫描生成的深度图和由mesh地图生成的渲染视图，我们提出一种新的观测模型，并将其融合进了蒙特卡洛定位框架，达到了更好的定位效果。我们在不同环境中使用不同的雷达进行了实验，结果证明了方法的准确与可靠。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>本文与2021.4.25推荐的“Robust Place Recognition using an Imaging Lidar”在雷达数据的处理上都为生成深度图，不过那一篇的思路为使用视觉重定位的方法（DBoW），本篇的思路为蒙特卡洛定位(MCL)。</li>
<li>本文对MCL公式的修改如图4所示，主要考虑了由点云生成的深度图和由地图生成的深度图的不同。</li>
</ol>
<p><strong>论文地址：<a href="https://arxiv.org/pdf/2105.12121.pdf">https://arxiv.org/pdf/2105.12121.pdf</a></strong><br><strong>开源代码：<a href="https://github.com/PRBonn/range-mcl">https://github.com/PRBonn/range-mcl</a></strong></p>
<img src="/2021/06/10/0607/1.png" class>
<img src="/2021/06/10/0607/2.png" class>
<img src="/2021/06/10/0607/3.png" class>
<img src="/2021/06/10/0607/4.png" class>
<img src="/2021/06/10/0607/5.png" class>
<img src="/2021/06/10/0607/6.png" class>
<img src="/2021/06/10/0607/7.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>localization</tag>
      </tags>
  </entry>
  <entry>
    <title>0609：Poisson Surface Reconstruction for LiDAR Odometry and Mapping</title>
    <url>/2021/11/04/0609/</url>
    <content><![CDATA[<p><em>作者:I. Vizzo， X. Chen， N. Chebrolu， J. Behley and C. Stachniss</em><br><em>机构:University of Bonn</em><br><em>发表:ICRA 2021</em></p>
<p>注：本篇文章看起来像是昨日文章的前置工作。<br><strong>Abstract</strong><br>在本文中，我们提出了一种激光SLAM的新的方法，专注于提高建图的精度，并于此同时估计位姿。我们使用frame-to-mesh的ICP，并且通过泊松表面重建获得triangle mesh来表示地图。我们通过滑动窗口的方式进行表面重建，这样我们获得了准确的局部地图，很合适进行配准，并且可以组装进全局地图。这让我们可以比surfle或TSDF等形式的3D地图展示更多的几何细节。我们的实验定性并定量地展示了， 我们的地图有着比别的地图更高的几何准确性。我们还表明，我们的地图是紧凑的，并且可以通过一种新的方法用于雷达里程计。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>所提出的地图的好处：</li>
<li>对环境几何信息更精确的表示；</li>
<li>更高的储存效率；</li>
<li>新的frame-mesh的配准算法。</li>
<li>对于每次扫描进行3个步骤：计算每个点的法线；将scan配准到local map（见图2）；将配准好的scan融合进global map。</li>
<li>文章还进行了mesh post-processing，见图3。具体的，去除了度数较少的顶点（意味着不是很可靠）。</li>
</ol>
<p><strong>论文地址：<a href="http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2021icra.pdf">http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2021icra.pdf</a></strong><br><strong>开源代码：<a href="https://github.com/PRBonn/puma">https://github.com/PRBonn/puma</a></strong><br><strong>视频资料：<a href="https://www.bilibili.com/video/BV1R5411M75t">https://www.bilibili.com/video/BV1R5411M75t</a></strong></p>
<img src="/2021/11/04/0609/1.png" class>
<img src="/2021/11/04/0609/2.png" class>
<img src="/2021/11/04/0609/3.png" class>
<img src="/2021/11/04/0609/4.png" class>
<img src="/2021/11/04/0609/5.png" class>
<img src="/2021/11/04/0609/6.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>开源代码</tag>
      </tags>
  </entry>
  <entry>
    <title>0613：OverlapNet:Loop Closing for LiDAR-based SLAM</title>
    <url>/2021/11/04/0613/</url>
    <content><![CDATA[<p><em>作者:Xieyuanli Chen，Olga Vysotska，Thomas Läbe，Alexandre Haag，Andres Milioto，Jens Behley，Timo Röhling，Cyrill Stachniss</em><br><em>机构:University of Bonn</em><br><em>发表:RSS 2020</em></p>
<p><strong>Abstract</strong><br>在本文中，我们旨在解决激光SLAM中回环检测的问题。我们使用DNN处理激光经过计算得到的各种数据来寻找闭环，估计两张深度图的重叠度，并获得两帧之间的偏航角（yaw）。基于这种预测，我们将这种闭环检测的手段融入进了现有的SLAM系统中。为了证明泛化性能，我们在KITTI数据集上进行训练，在福特校园数据集（Ford campus dataset）上进行测试。结果证明，即使是没有见过的场景，闭环检测也能正常运行。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>网路的输入包括，雷达产生的深度图，向量图，强度图，语义图，具体的网络结构见图4；</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>通过网络预测overlap值和偏航角（yaw）；</li>
<li>结合里程计的信息，与1中提到的预测信息，检测闭环；</li>
<li>提升了整体的SLAM效果；</li>
<li>在没有先验位姿信息的情况下，解决了闭环问题；</li>
<li>可以使用OverlapNet的预测结果初始化ICP。</li>
</ol>
<p><strong>论文地址：<a href="https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf">https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf</a></strong><br><strong>开源代码：<a href="https://github.com/PRBonn/OverlapNet">https://github.com/PRBonn/OverlapNet</a></strong></p>
<img src="/2021/11/04/0613/1.png" class>
<img src="/2021/11/04/0613/2.png" class>
<img src="/2021/11/04/0613/3.png" class>
<img src="/2021/11/04/0613/4.png" class>
<img src="/2021/11/04/0613/5.png" class>
<img src="/2021/11/04/0613/6.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>localization</tag>
        <tag>开源代码</tag>
      </tags>
  </entry>
  <entry>
    <title>0629 SegMatch:Segment Based Place Recognition in 3D Point Clouds</title>
    <url>/2021/06/29/0629/</url>
    <content><![CDATA[<p><em>作者:R. Dubé, D. Dugas, E. Stumm, J. Nieto, R. Siegwart, and C. Cadena</em><br><em>机构:ETHZ</em><br><em>发表:ICRA 2017</em></p>
<p><strong>Abstract</strong><br>重定位问题通常是通过基于图像的方式解决的。基于局部特征的方法会受到运动模糊和环境变化的影响，基于全局特征的会受到视角变化的影响。我们提出了SegMatch，一种基于3D点云分割的重定位算法。分割提供了全局特征和局部特征之间很好的折中选项，可以利用二者的优点，同时克服二者的缺点。SegMatch不假设可以获得完美的分割，并且不对环境中可能出现的物体进行假设，这可以保证算法在大型非结构化的场景中进行稳定的运行。我们定量地证明了SegMatch可以以1Hz的频率在KITTI数据集中获得准确的定位信息。更进一步，我们展示了我们的算法可以实时检测回环。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>如图二所示，算法主要分为四个部分:点云分割，特征提取，分割匹配，几何检验。</li>
<li>分割采用论文“On the segmentation of 3d lidar point clouds”中所提到的Cluster-All Method方法。如图3所示。</li>
<li>特征提取，对每一个分割后的聚类进行提取。文章中提到两类：基于特征值的特征：linearity, planarity, scattering, omnivariance, anisotropy, eigenentropy and change of curvature；基于直方图的特征：1个640维的特征，由十个直方图获得。</li>
<li>分割匹配：将上述特征放入随机森林进行训练，将匹配问题转化为分类问题，分为一类的即为同一物体。算法中一些参数如图4所示。</li>
<li>几何检验：使用RANSAC进行几何一致性检验。</li>
</ol>
<p><strong>论文地址：<a href="https://arxiv.org/pdf/1609.07720.pdf">https://arxiv.org/pdf/1609.07720.pdf</a></strong><br><strong>开源代码：<a href="https://github.com/ethz-asl/segmap">https://github.com/ethz-asl/segmap</a></strong></p>
<img src="/2021/06/29/0629/1.png" class>
<img src="/2021/06/29/0629/2.png" class>
<img src="/2021/06/29/0629/3.png" class>
<img src="/2021/06/29/0629/4.png" class>
<img src="/2021/06/29/0629/5.png" class>
<img src="/2021/06/29/0629/6.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>localization</tag>
      </tags>
  </entry>
  <entry>
    <title>0811 SLAM++:Simultaneous Localisation and Mapping at the Level of Objects</title>
    <url>/2021/08/11/0811/</url>
    <content><![CDATA[<p><em>作者:Renato F. Salas-Moreno,Richard A. Newcombe, Hauke Strasdat, Andrew J. Davison</em><br><em>机构:Imperial College London, University of Washington</em><br><em>发表:CVPR 2013</em></p>
<p><strong>Abstract</strong><br>我们提出了一种新的物体级的SLAM方法，其充分利用了许多场景由重复的，特定的物体和结构组成。当手持深度相机浏览杂乱场景时，实时3D物体识别和追踪提供了6自由度的相机-物体的约束，这个可以构成一个精确的物体图，由高效的位姿图进行持续优化。这提供了SLAM系统的描述和预测能力，可以进行稠密表面重建，而且压缩了表示所需的代价。物体图使得每一帧中基于ICP的追踪更加精确，并且可以高效地发现未探索区域的新物体。我们展示了大而杂乱的场景中实时增量的SLAM，包含了回环检测，重定位，检测动态物体，并且生成具有实现潜力的物体级场景描述。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>
<img src="/2021/08/11/0811/1.png" class>
<img src="/2021/08/11/0811/2.png" class>
<img src="/2021/08/11/0811/3.png" class>
<img src="/2021/08/11/0811/4.png" class>
<img src="/2021/08/11/0811/5.png" class>
<img src="/2021/08/11/0811/6.png" class>
<img src="/2021/08/11/0811/7.png" class>
]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>object</tag>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>20220422 A decentralized framework for simultaneous calibration, localization and mapping with multiple LiDARs</title>
    <url>/2022/04/22/20220422/</url>
    <content><![CDATA[<p><em>作者:Jiarong Lin, Xiyuan Liu and Fu Zhang</em><br><em>机构:HKU</em><br><em>发表:IROS 2020</em></p>
<p><strong>Abstract</strong><br>单个激光雷达经常遭到环境问题（温度颠簸等）导致的硬件问题（比如断连），或因为缺乏足够的几何特征导致的退化，这个问题对于小FOV固态激光来说更为严重。为了提高在SLAM中的鲁棒性，我们开发了一个分布式框架，用于多激光雷达的标定定位和建图。我们提出的框架基于EKF，但是是分布的实现形式。这样可以将每个雷达的密集计算分布到小的计算单元上，并且避免单点故障问题。然后，一辆搭载5个低功耗雷达，以1.3m/s的速度运行的小车被用来做实验。提出的方法可以成功估计状态，并且计算激光雷达外参。定位误差最高0.2%. 代码已开源。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：<a href="https://arxiv.org/pdf/2007.01483">https://arxiv.org/pdf/2007.01483</a></strong><br><strong>开源代码：<a href="https://github.com/hku-mars/decentralized_loam">https://github.com/hku-mars/decentralized_loam</a></strong><br><strong>硬件模型：<a href="https://github.com/hku-mars/lidar_car_platfrom">https://github.com/hku-mars/lidar_car_platfrom</a></strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>multi</tag>
      </tags>
  </entry>
  <entry>
    <title>20220506 Generalized-ICP</title>
    <url>/2022/05/06/20220506/</url>
    <content><![CDATA[<p><em>作者:</em><br><em>机构:</em><br><em>发表:</em></p>
<p><strong>Abstract</strong></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>20220507 Voxelized GICP for Fast and Accurate 3D Point Cloud Registration</title>
    <url>/2022/05/06/20220507/</url>
    <content><![CDATA[<p><em>作者:Kenji Koide, Masashi Yokozuka, Shuji Oishi, and Atsuhiko Banno</em><br><em>机构: AIST</em><br><em>发表: ICRA 2021</em></p>
<p><strong>Abstract</strong><br>本文提出了体素化的GICP，称之为VGICP，来实现快速准确的3D配准。在GICP的基础上，通过体素化来避免大量的最近邻查询。与NDT（通过点的位置计算体素分布）相比，我们通过aggregate 每个点的分布，来估计体素的分布。这个操作可以高效地并行处理优化，15000个点在CPU 30Hz， 在GPU 120Hz。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<ol>
<li>GICP弱点：依赖最近邻搜索，耗时长。NDT弱点：对voxel分辨率很敏感，对不同场景和传感器需要设置不同的分辨率。</li>
<li>multi-point distribution aggregation approach的含义为，对每个voxel里的点，取其分布的平均，来代替GICP的点对点的模式。</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>提出一个multi-point distribution aggregation approach 来鲁棒地估计体素的分布。</li>
<li>提出VGICP算法和GICP一样准，但是快很多。</li>
<li>开源。</li>
</ol>
<p><strong>论文地址：<a href="https://easychair.org/publications/preprint/ftvV">https://easychair.org/publications/preprint/ftvV</a></strong><br><strong>开源代码：<a href="https://github.com/SMRT-AIST/fast_gicp">https://github.com/SMRT-AIST/fast_gicp</a></strong></p>
<img src="/2022/05/06/20220507/1.png" class>
<img src="/2022/05/06/20220507/2.png" class>
<img src="/2022/05/06/20220507/3.png" class>]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>LiDAR</tag>
        <tag>registration</tag>
      </tags>
  </entry>
  <entry>
    <title>20220508 Globally Consistent 3D LiDAR Mapping with GPU-accelerated GICP Matching Cost Factors</title>
    <url>/2022/05/06/20220508/</url>
    <content><![CDATA[<p><em>作者:</em><br><em>机构:</em><br><em>发表:</em></p>
<p><strong>Abstract</strong></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>20220521 FAST-LIVO:Fast and Tightly-coupled Sparse-Direct LiDAR-Inertial-Visual Odometry</title>
    <url>/2022/05/21/20220521/</url>
    <content><![CDATA[<p><em>作者:Chunran Zheng∗ , Qingyan Zhu∗ , Wei Xu, Xiyuan Liu, Qizhi Guo and Fu Zhang</em><br><em>机构:HKU</em><br><em>发表:arxiv</em></p>
<p><strong>Abstract</strong><br>为了鲁棒准确地估计位姿，多传感器融合是一个有效的方法。本文提出FAST-LIVO，一个快速的激光惯性视觉融合里程计系统，构建了两个紧耦合并且是直接法的里程计子系统，VIO和LIO。LIO使用原始点云来构建增量式地图。地图点添加时绑定了图像patch，这些patch可以用在VIO系统中通过直接最小化光度误差来对齐新的图像。为了更进一步提升VIO的鲁棒性和准确性，一个新的外点拒绝方法被提出来拒绝不稳定的地图点（在边缘或者被遮挡的）。实验在数据集和自己收集的数据上被执行。结果展现了提出的系统超过了别的竞争对手，并且可以解决有挑战的场景。该套系统可以支持旋转式和LIVOX两种雷达，并且可以在电脑和ARM上实时运行。</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>fusion</tag>
      </tags>
  </entry>
  <entry>
    <title>20220509 FasterGICP:Acceptance-Rejection Sampling Based 3D Lidar Odometry</title>
    <url>/2022/05/06/20220509/</url>
    <content><![CDATA[<p><em>作者:</em><br><em>机构:</em><br><em>发表:</em></p>
<p><strong>Abstract</strong></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
  <entry>
    <title>20220526 R3LIVE:A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package</title>
    <url>/2022/05/26/20220526/</url>
    <content><![CDATA[<p><em>作者:Jiarong Lin and Fu Zhang</em><br><em>机构:HKU</em><br><em>发表:ICRA 2022</em></p>
<p><strong>Abstract</strong><br>在本文中，我们提出了一个新的LIV融合的框架R3LIVE，该框架由两个子系统组成，LIO和VIO。LIO以FAST-LIO为基础，利用激光雷达构建全局地图的空间结构。VIO利用相机渲染地图的颜色。更详细的，VIO为利用最小化光度误差（frametomap）的直接法.</p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>每日论文分享</tag>
        <tag>IMU</tag>
        <tag>fusion</tag>
      </tags>
  </entry>
  <entry>
    <title>20220527 PanopticFusion:Online Volumetric Semantic Mapping at the Level of Stuff and Things</title>
    <url>/2022/05/27/20220527/</url>
    <content><![CDATA[<p><em>作者:Gaku Narita, Takashi Seno, Tomoya Ishikawa, Yohsuke Kaji</em><br><em>机构:sony</em><br><em>发表:IROS 2019</em></p>
<p><strong>Abstract</strong></p>
<span id="more"></span>
<p><strong>一些信息：</strong></p>
<p><strong>主要贡献：</strong></p>
<p><strong>论文地址：</strong><br><strong>开源代码：</strong></p>







]]></content>
      <categories>
        <category>每日论文分享</category>
      </categories>
      <tags>
        <tag>semantic</tag>
        <tag>每日论文分享</tag>
      </tags>
  </entry>
</search>
